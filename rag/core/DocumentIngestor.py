import os
from typing import List, Optional, Dict
from langchain.schema import Document
from rag.core.indexing import parse_file, chunk_file
from src.models.embedding import get_embedding_model
from rag.core.Milvus import MilvusStorage
from configs.settings import *


class DocumentIngestor:
    def __init__(
            self,
            milvus_config: Dict,
            embedding_config: Dict,
            chunk_size: int = 1000,
            chunk_overlap: int = 100,
            ocr_enabled: bool = False,
            ocr_det_threshold: float = 0.3,
    ):
        """
        æ–‡ä»¶ -> Chunk -> Embedding -> å­˜å…¥ Milvus çš„é›†æˆç±»

        Args:
            milvus_config: åˆå§‹åŒ–MilvusStorageçš„é…ç½®å­—å…¸
            embedding_config: åˆå§‹åŒ–Embeddingæ¨¡å‹çš„é…ç½®å­—å…¸
            chunk_size: æ–‡æœ¬å—çš„æœ€å¤§é•¿åº¦
            chunk_overlap: æ–‡æœ¬å—ä¹‹é—´çš„é‡å é•¿åº¦
            ocr_enabled: æ˜¯å¦å¯¹PDFå¯ç”¨OCR
            ocr_det_threshold: OCRæ£€æµ‹é˜ˆå€¼
        """
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        self.ocr_enabled = ocr_enabled
        self.ocr_det_threshold = ocr_det_threshold

        self.embedder = get_embedding_model(embedding_config)
        self.store = MilvusStorage(**milvus_config)

    def ingest_single_file(self, file_path: str):
        """
        å¤„ç†å•ä¸ªæ–‡ä»¶ï¼Œå¹¶æ’å…¥å‘é‡æ•°æ®åº“ã€‚

        Args:
            file_path: æ–‡ä»¶è·¯å¾„
        """
        print(f"ğŸ“„ æ­£åœ¨å¤„ç†æ–‡ä»¶: {file_path}")
        chunks = chunk_file(
            file_path=file_path,
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
            do_ocr=self.ocr_enabled,
            ocr_det_threshold=self.ocr_det_threshold
        )

        texts = [doc.page_content for doc in chunks]
        embeddings = self.embedder.batch_encode(texts)

        for doc, embedding in zip(chunks, embeddings):
            doc.metadata["embedding"] = embedding

        self.store.insert(chunks)
        print(f"âœ… æ–‡ä»¶ {file_path} å¤„ç†å®Œæˆå¹¶å­˜å…¥å‘é‡æ•°æ®åº“ï¼")

    def ingest_directory(self, directory_path: str, suffixes: Optional[List[str]] = None):
        """
        æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹ä¸‹çš„æ–‡ä»¶ã€‚
        Args:
            directory_path: æ–‡ä»¶å¤¹è·¯å¾„
            suffixes: æ–‡ä»¶åç¼€åˆ—è¡¨ï¼Œå¦‚[".pdf", ".docx", ".txt"]
        """
        suffixes = suffixes or [".pdf", ".docx", ".txt", ".md"]
        print(f"ğŸ“ æ‰«æç›®å½•: {directory_path}")

        for root, dirs, files in os.walk(directory_path):
            for file in files:
                if any(file.lower().endswith(ext) for ext in suffixes):
                    file_path = os.path.join(root, file)
                    self.ingest_single_file(file_path)

    def close(self):
        """å…³é—­ Milvus è¿æ¥"""
        self.store.close()
        print("ğŸ”Œ å‘é‡æ•°æ®åº“è¿æ¥å·²å…³é—­ï¼")


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    milvus_config = {
        "collection_name": "documents_collection",
        "overwrite": True,
        "dim": 1024,
        "host": "localhost",
        "port": "19530",
        "openai_base_url": MODEL_API_BASE,
        "openai_api_key": MODEL_API_KEY,
        "embedding_model": EMBEDDING_MODEL
    }

    embedding_config = {
        "enable_knowledge_base": True,
        "embed_model": "local/bge-large-zh-v1.5"
    }

    ingestor = DocumentIngestor(
        milvus_config=milvus_config,
        embedding_config=embedding_config,
        chunk_size=500,
        chunk_overlap=100,
        ocr_enabled=True
    )

    # å•æ–‡ä»¶å¯¼å…¥ç¤ºä¾‹
    ingestor.ingest_single_file("/data/Langagent/deepdoc/data/picture.pdf")

    # æ•´ä¸ªæ–‡ä»¶å¤¹å¯¼å…¥ç¤ºä¾‹
    # ingestor.ingest_directory("/data/docs")

    ingestor.close()
